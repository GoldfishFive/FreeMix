_BASE_: ../voc-11k-20/mask2former_R50_bs16_20k.yaml
MODEL:
  META_ARCHITECTURE: "OpenVocabulary"
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 27 #only used in set criterion  34(all)-7(unseen)=27(seen)
    EMBEDDING_DIM: 512
    EMBED_LAYERS: 2
  CLIP_ADAPTER:
    PROMPT_LEARNER: "learnable"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.7
    SEPERATE_ADAPTER: False
    REGION_CLIP_ADAPTER:
      PROMPT_LEARNER: "learnable"
#INPUT:
#  TASK_NAME: ["semantic segmentation.", "panoptic segmentation."]
SOLVER:
  IMS_PER_BATCH: 4
  TEST_IMS_PER_BATCH: 4
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("campot_base_sem_seg_train",)
#  TEST: ("campot_sem_seg_test",)
#  TEST: ("camvid_sem_seg_test",)
#  TEST: ("potsdam_sem_seg_test",)
  TEST: ("camvid_sem_seg_test", "potsdam_sem_seg_test",)

OUTPUT_DIR: ./freeseg_output/campot/Baseline_CamPot-base_mask2former_R50_bs16_20k/
